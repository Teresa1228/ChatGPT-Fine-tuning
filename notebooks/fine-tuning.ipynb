{"cells":[{"cell_type":"markdown","metadata":{"id":"nU6AVuvzqDu1"},"source":["**链接到自己的谷歌云盘**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Yh-WIMsrNl6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Gq4QA-Tlr_NJ"},"source":["## **1.安装依赖**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6680,"status":"ok","timestamp":1693458761593,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"Nf_ibxWDr7zC","outputId":"de4710fa-eae8-4010-fe9d-fc47c9853ca2"},"outputs":[],"source":["%pip install openai requests"]},{"cell_type":"markdown","metadata":{"id":"-IIXlk0PtFs0"},"source":["## **2.引入openai环境**\n","\n","注意此处需要填写您自己的api_key"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":561,"status":"ok","timestamp":1693454669883,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"llaD5Wv-qDu4"},"outputs":[],"source":["import openai\n","import os\n","api_key = 'sk-' ## your api key here\n","openai.api_key  = api_key"]},{"cell_type":"markdown","metadata":{"id":"DZ6BLzvFqDu5"},"source":["## **3.数据处理**\n","将数据格式处理成标准化的JSON-L格式，即Chat completions API中所要求的messages数组形式，每行一个如下所示的JSON对象。\n","``` JSON\n","{\"messages\": [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": \"\"}, {\"role\": \"assistant\", \"content\": \"\"}]}\n","```"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":606,"status":"ok","timestamp":1693454358213,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"T4WZ9kWPvWvT"},"outputs":[],"source":["import json\n","\n","# 打开收集的数据文件\n","with open('/content/drive/MyDrive/openai/data/raw/training_data.txt', 'r', encoding='utf-8') as file:\n","    content = file.read()\n","\n","# 以三个连续的换行符分割成段落\n","paragraphs_level1 = content.split('\\n\\n\\n')\n","\n","# 构建消息列表\n","messages = []\n","\n","for i, paragraph_level1 in enumerate(paragraphs_level1, start=1):\n","    # 在每个段落内再以两个连续的换行符分割内容\n","    paragraphs_level2 = paragraph_level1.split('\\n\\n')\n","\n","    # 初始化消息对象\n","    message = {\"messages\": []}\n","\n","    # 添加系统消息\n","    message[\"messages\"].append({\"role\": \"system\", \"content\": \"你是一名翻译\"})\n","\n","    # 添加第二级段落内容到不同角色的消息\n","    for j, paragraph_level2 in enumerate(paragraphs_level2, start=1):\n","        role = \"user\" if j % 2 == 1 else \"assistant\"\n","        message[\"messages\"].append({\"role\": role, \"content\": paragraph_level2})\n","\n","    # 将消息对象添加到消息列表\n","    messages.append(message)\n","\n","# 将消息列表写入到 chat_data.jsonl 文件\n","with open('/content/drive/MyDrive/openai/data/processed/chat_data.jsonl', 'w', encoding='utf-8') as jsonl_file:\n","    for message in messages:\n","        jsonl_file.write(json.dumps(message, ensure_ascii=False) + '\\n')\n"]},{"cell_type":"markdown","metadata":{"id":"b1n-zQ5Lv59O"},"source":["## **4.上传数据**\n","将上一步处理完成的JSON-L格式数据，通过files接口上传到OpenAI服务器，获取文件id"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1297,"status":"ok","timestamp":1693454735587,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"ntaUzoOhqDu5","outputId":"290c2743-5720-46ac-d0f3-350236a7c208"},"outputs":[],"source":["import requests\n","import openai\n","\n","url = \"https://api.openai.com/v1/files\"\n","headers = {\n","    \"Authorization\": f\"Bearer {api_key}\"\n","}\n","\n","payload = {\n","    \"purpose\": \"fine-tune\",\n","}\n","files = {\n","    \"file\": open(\"/content/drive/MyDrive/openai/data/processed/chat_data.jsonl\", \"rb\")\n","}\n","\n","response = requests.post(url, headers=headers, data=payload, files=files)\n","response_text = response.text\n","print(response_text)\n","response_json = json.loads(response_text)  # 将响应文本转换为 JSON 字典\n","file_id = response_json[\"id\"]\n","print(file_id)"]},{"cell_type":"markdown","metadata":{"id":"mikUtQOgqDu6"},"source":["## **5.创建fine-tuning任务**\n","通过fine_tuning/jobs接口，将上一步上传的数据文件id传入，创建fine-tuning任务，并获取任务id"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1187,"status":"ok","timestamp":1693456435643,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"itw_-upIqDu6","outputId":"c0f23669-ff4f-4533-8cd0-bad962791802"},"outputs":[],"source":["import requests\n","\n","url = \"https://api.openai.com/v1/fine_tuning/jobs\"\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {api_key}\"\n","}\n","data = {\n","    \"training_file\": f\"{file_id}\",\n","    \"model\": \"gpt-3.5-turbo-0613\"\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","print(response.text)\n","response_json = json.loads(response.text)  # 将响应文本转换为 JSON 字典\n","fine_tuning_job_id = response_json[\"id\"]\n","print(fine_tuning_job_id)"]},{"cell_type":"markdown","metadata":{"id":"zm9SXorlqDu6"},"source":["## **6.查看微调进度**\n","通过fine_tuning/jobs接口，传入上一步获取的微调任务id，获得进行中的微调任务状态。\n","如果status的值时running，说明该模型还在训练中，此时fine_tuned_model里面没有值，需要继续等待。\n","\n","如果status是succeeded，说明已经训练完成，此时通过fine_tuned_model的值，可以得到微调成功的模型id\n","\n","如果训练成功，开发者账号对应的邮箱，也会收到一封电子邮件，里面会包含模型id。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":486,"status":"ok","timestamp":1693458592459,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"x-o3ulotqDu6","outputId":"64838d29-8786-4fd9-8a1e-5c288aeea025"},"outputs":[],"source":["import requests\n","\n","url = f\"https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}\"\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {api_key}\"\n","}\n","\n","response = requests.get(url, headers=headers)\n","print(response.text)\n","response_json = json.loads(response.text)  # 将响应文本转换为 JSON 字典\n","fine_tuned_model = response_json[\"fine_tuned_model\"]\n","print(fine_tuned_model)"]},{"cell_type":"markdown","metadata":{"id":"hZ29g1Ib0sUW"},"source":["## **7.测试模型**\n","通过Completion API，对微调成功的模型进行效果测试。\n","我们可以按正常GPT模型，例如GPT-3.5-turbo的调用方式，来调用微调好的模型，访问参数完全相同。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10760,"status":"ok","timestamp":1693458605358,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"Oj8rwOhWqDu6","outputId":"cec235e8-0ab7-43c1-9dbe-1f5d2c438b4d"},"outputs":[],"source":["response = openai.ChatCompletion.create(\n","    model=f\"{fine_tuned_model}\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"这里写入需要检测的system内容\"},\n","        {\"role\": \"user\", \"content\": \"这里输入需要检测的问题内容\"}\n","\n","    ]\n",")\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["## 总结\n","至此，一个免安装的微调流程就完成了。需要注意的是，其中用到的数据样本较少，仅用于演示微调的技术实现过程。当然，即使很少的数据也能完成微调，这是GPT-3.5-turbo的优势，但从工作的角度来看，我们仍有必要认真的准备和标记数据。"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
